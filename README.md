# Predicting Sentences with Pretrained LLMs
A practical assignment for the course Natural Language Processing

This repository features a Jupyter notebook for the natural language generation project. It focuses on text generation conditioned on sentence beginnings,
using various pre-trained models like GPT2, GPT2-xl, T5, and XL-Net. The notebook explores different decoding methods to optimize parameters for text generation
and evaluates the results using Perplexity scores.
